{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1deb7e63-0f2a-400b-a469-3c00e0155fa8",
   "metadata": {},
   "source": [
    "# Facenet recreation\n",
    "Google facenet recreation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ab0145-5c39-48a4-a6b3-65ecf44edead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "from matplotlib import image\n",
    "import glob as glob\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchinfo import summary\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "  print(\"Using the GPU!\")\n",
    "else:\n",
    "  print(\"WARNING: Could not find GPU! Using CPU only. If you want to enable GPU, please to go Edit > Notebook Settings > Hardware Accelerator and select GPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c3927d-59f0-471c-9ec0-91d4ad88a695",
   "metadata": {},
   "source": [
    "# Build Dataset from facenet\n",
    "using instructions from pytorch docs: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "Reading pairs to ensure that muiltiple faces of a single person \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27336115-5844-4787-9294-8fe5afde62ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabledFacesWild(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        label_dict = []\n",
    "        with open(annotations_file) as f:\n",
    "            for line in f:\n",
    "                name, i1, i2 = line.split('\\t')\n",
    "                label_dict.append({\n",
    "                    \"label\": name,\n",
    "                    \"img1\": f\"{name}/{i1:04d}.jpg\",\n",
    "                    \"img2\": f\"{name}/{i2:04d}.jpg\"\n",
    "                })\n",
    "        self.img_labels = pd.DataFrame.from_records(label_dict)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels) * 2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair_num = idx // 2\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[pair_num, (idx % 2) + 1])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[pair_num, 0]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee94ce5-1029-4fe2-b740-3f88501f8be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually load data\n",
    "num_train_pairs = 1100\n",
    "num_test_pairs = 500\n",
    "batch_size = 40\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# construct the dataloader\n",
    "train_data = Edges2Image('./pairsDevTrain.txt', './lfw/', transform)\n",
    "test_data = Edges2Image('./pairsDevTest.txt', './lfw/', transform)\n",
    "train_loader = DataLoader(train_data, batch_size=50, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=50, shuffle=False)\n",
    "\n",
    "# todo figure out actual batching while including groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d190bd8c-ffa6-4bae-8d13-5de9a4dac358",
   "metadata": {},
   "source": [
    "# Create Facenet Model\n",
    "Facenet model https://arxiv.org/pdf/1503.03832.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261b9419-5379-4000-b1de-b2ea3ef7a0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fcaa6b-902b-4f5c-b48b-2ec1aa46ee89",
   "metadata": {},
   "source": [
    "# Train Facenet Model\n",
    "training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28df9202-813b-4d3e-8b5a-d4f5e6167eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cc018e-1f6d-4840-ab6f-f2bb505cbdc0",
   "metadata": {},
   "source": [
    "# Test Facenet Model\n",
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694dafc5-06c2-486c-997b-b4f97ac4f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
